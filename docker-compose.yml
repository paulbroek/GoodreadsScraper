version: "3.9"
services:
  scrape-goodreads-list:
    build: .
    container_name: scrape-goodreads-list
    # restart: unless-stopped
    # network_mode:  host
    # environmnet can be set in terminal using export LIST_TO_SCRAPE=some_list...
    # environment:
    # - LIST_TO_SCRAPE=79365.Favorite_herbal_natural_health_books
    # - OUTPUT_FILE_SUFFIX=best_herbal_books
    # - LIST_TO_SCRAPE=692.Best_Science_Books_Non_Fiction_Only
    # - OUTPUT_FILE_SUFFIX=692.Best_Science_Books_Non_Fiction_Only
    # - LIST_TO_SCRAPE=30903.Required_Reading_for_Success
    # - OUTPUT_FILE_SUFFIX=30903.Required_Reading_for_Success
    # - LIST_TO_SCRAPE=1.Best_Books_Ever
    # - OUTPUT_FILE_SUFFIX=best_books
    command:
      - /bin/bash
      - -c
      - |
        cd /mnt_src
        scrapy crawl \
          --logfile=scrapy.log \
          -a start_page_no=1 \
          -a end_page_no=2 \
          -a list_name=${LIST_TO_SCRAPE} \
          -s OUTPUT_FILE_SUFFIX=${LIST_TO_SCRAPE} \
          list
      # if you want to substitute lists from 'environment' section of this file, make sure to use double curly braces variable injection: ${{LIST_TO_SCRAPE}}

    volumes:
      - /home/${USER}/repos/GoodreadsScraper:/mnt_src

  scrape-goodreads-author-list:
    build: .
    container_name: scrape-goodreads-author-list
    # environment:
    # - LIST_TO_SCRAPE=4562806.Dan_S_Kennedy
    command:
      - /bin/bash
      - -c
      - |
        cd /mnt_src
        scrapy crawl \
          --logfile=scrapy.log \
          -a start_page_no=1 \
          -a end_page_no=50 \
          -a list_name=${LIST_TO_SCRAPE} \
          -s OUTPUT_FILE_SUFFIX=${LIST_TO_SCRAPE} \
          author-list
      # if you want to substitute lists from 'environment' section of this file, make sure to use double curly braces variable injection: ${{LIST_TO_SCRAPE}}

    volumes:
      - /home/${USER}/repos/GoodreadsScraper:/mnt_src

  scrape-goodreads-redis:
    build: .
    container_name: scrape-goodreads-redis
    # restart: unless-stopped
    network_mode: host
    environment:
      - LIST_TO_SCRAPE=redis_books
      - OUTPUT_FILE_SUFFIX=redis_books
      - SCRAPE_GOODREADS_CONFIG_FILE=/home/paul/repos/misc-scraping/misc_scraping/scrape_goodreads/config/db.prod.cfg
    command:
      - /bin/bash
      - -c
      - |
        cd /mnt_src
        scrapy crawl \
          --logfile=scrapy.log \
          -s OUTPUT_FILE_SUFFIX=${LIST_TO_SCRAPE} \
          myspider_redis
          # redis

    volumes:
      - /home/${USER}/repos/GoodreadsScraper:/mnt_src
      - /home/${USER}/repos/misc-scraping/misc_scraping/scrape_goodreads/config:/home/paul/repos/misc-scraping/misc_scraping/scrape_goodreads/config

  scrape-goodreads-feather-author:
    build: .
    container_name: scrape-goodreads-feather-author
    # restart: unless-stopped
    environment:
      - LIST_TO_SCRAPE=all_author_books
      - OUTPUT_FILE_SUFFIX=all_author_books
      # - REDIS_HOST=213.93.184.218
      - REDIS_HOST=127.0.0.1
      - REDIS_PORT=6382
      # - REDIS_PORT=6382
    command:
      - /bin/bash
      - -c
      - |
        cd /mnt_src
        scrapy crawl \
          --logfile=scrapy.log \
          -a start_page_no=1 \
          -a end_page_no=3 \
          -a list_name=notused \
          -s OUTPUT_FILE_SUFFIX=myauthor \
          feather_author_list

    volumes:
      - /home/${USER}/repos/GoodreadsScraper:/mnt_src

  scrape-goodreads-pg-author:
    build: .
    container_name: scrape-goodreads-pg-author
    # restart: unless-stopped
    environment:
      - LIST_TO_SCRAPE=all_author_books
      - OUTPUT_FILE_SUFFIX=all_author_books
      - REDIS_HOST=213.93.184.218
    command:
      - /bin/bash
      - -c
      - |
        cd /mnt_src
        scrapy crawl \
          --logfile=scrapy.log \
          -a start_page_no=1 \
          -a end_page_no=3 \
          -a list_name=notused \
          -s OUTPUT_FILE_SUFFIX=myauthor \
          pg_author_list

    volumes:
      - /home/${USER}/repos/GoodreadsScraper:/mnt_src
